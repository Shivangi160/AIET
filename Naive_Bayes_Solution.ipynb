{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU40Hm_2eFqM",
        "colab_type": "text"
      },
      "source": [
        "**Import the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxdXnHV1eDwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZWSe20QXZiD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Data Exploration** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQVun14fXjG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "843ad269-2ae6-467a-85d4-66a94bf8ecca"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "iris.feature_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4eA7EE_Xwg1",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/mDC1KSt/petal-sepal.png\" alt=\"petal-sepal\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u2WbWVLX31J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dac2480-bfce-4270-f2cb-6a559c12e2d9"
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryRF0X90YCnW",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://ibb.co/8sJhx0R\"><img src=\"https://i.ibb.co/h9kqdyn/iris.png\" alt=\"iris\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nKYhLPLeYjc",
        "colab_type": "text"
      },
      "source": [
        "**Loading and splitting the dataset into train and testsets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOWi9bLAxB6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e9b11b7-d86c-45fd-f5b3-1e89755bf93e"
      },
      "source": [
        "len(iris.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9lxI9rIy8wT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f6a0507-ce55-435b-e047-615e114b58f6"
      },
      "source": [
        "[0]*10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "potkSmjEedRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "# Please fill in the below function which can be used to split the data in 80:20 ratio and return 4 numpy arrays- train_x, train_y, test_x, test_y\n",
        "# shapes- train_x: (0.8*len(iris.data),4), train_y : (0.8*len(iris.data),),test_x:(0.2*len(iris.data),4) , test_y:(0.2*len(iris.data),) \n",
        "def dataset_splitter(iris):\n",
        "  \n",
        "  # space for code\n",
        "  samples_0=[]\n",
        "  samples_1=[]\n",
        "  samples_2=[]\n",
        "  for i,row in enumerate(iris.data):\n",
        "    if iris.target[i]==0:    \n",
        "      samples_0.append(list(row))\n",
        "    elif iris.target[i]==1:\n",
        "      samples_1.append(list(row))\n",
        "    elif iris.target[i]==2:\n",
        "      samples_2.append(list(row))\n",
        "  train_x=(np.array(samples_0[:40]+samples_1[:40]+samples_2[:40]))\n",
        "  train_y=np.array([0]*40+[1]*40+[2]*40)\n",
        "  test_x=np.array(samples_0[40:]+samples_1[40:]+samples_2[40:])\n",
        "  test_y=np.array([0]*10+[1]*10+[2]*10)\n",
        "  \n",
        "  return (train_x, train_y, test_x, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29nwz-fhsV9Y",
        "colab_type": "text"
      },
      "source": [
        "**Function to calculate mean and variance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rywp-d8ahegq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function returns the mean and variance across all dimensions of the input\n",
        "# returns: 1.mean : shape- (4,) 2.variance : shape- (4,) \n",
        "def mean_var_calculator(data):\n",
        "  \n",
        "  # space for code\n",
        "  mean = np.mean(data,axis=0)\n",
        "  var  = np.var(data,axis=0)\n",
        "  \n",
        "  return (mean, var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWAiScgesb_M",
        "colab_type": "text"
      },
      "source": [
        "**Calculating log posterior**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arnjuE-OXhlG",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "Posterior(X|\\sigma_c^{2},\\mu_c,class label=C)=\\Pi_{i=1}^{4} \\frac{1}{\\sqrt{2\\pi}\\sigma_c^2}e^{\\frac{-(x_i-\\mu_c)^2}{2\\sigma_c^2}}.P(C)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQHmqYhFh2_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this function takes 3 parameters as input- \n",
        "#1. data sample for which the posterior is to be calculated\n",
        "#2. Mean, Variance of the gaussian w.r.t which posterior is to be estimated\n",
        "#Assume a Uniform Prior on the class labels\n",
        "#return the log of posterior calculated- shape: X.shape[0]\n",
        "def calc_log_posterior(x,mean,var):\n",
        "  \n",
        "  # space for code\n",
        "  prior = np.log(0.33)\n",
        "  likelihood = -0.5 * np.sum(np.log(2. * np.pi * var)) -0.5 * np.sum(((x - mean) ** 2) /(var), 0)\n",
        "  posterior = prior + likelihood\n",
        "  \n",
        "  return (posterior)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0CLzcByUVZq",
        "colab_type": "text"
      },
      "source": [
        "   **Making predictions using the model that we have**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha5jNZVf1FaE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybhBVS3aoGF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inputs: 1. x- datapoint to which the prediction is to be calculated\n",
        "#        2. set_0 - a tuple of mean and variance for training samples belonging to class:0\n",
        "#           set_1 - a tuple of mean and variance for training samples belonging to class:1\n",
        "#           set_2 - a tuple of mean and variance for training samples belonging to class:2   \n",
        "#        3. class_label: integer in range:{0,1,2,3}\n",
        "def predict(x, set_0, set_1, set_2):\n",
        "  \n",
        "  # space for code\n",
        "  if calc_log_posterior(x,set_0[0],set_0[1])==max(calc_log_posterior(x,set_0[0],set_0[1]), calc_log_posterior(x,set_1[0],set_1[1]), calc_log_posterior(x,set_2[0],set_2[1])):\n",
        "    class_label = (0)\n",
        "  elif calc_log_posterior(x,set_1[0],set_1[1])==max(calc_log_posterior(x,set_0[0],set_0[1]), calc_log_posterior(x,set_1[0],set_1[1]), calc_log_posterior(x,set_2[0],set_2[1])):\n",
        "    class_label = (1)\n",
        "  else:\n",
        "    class_label = (2)\n",
        "  \n",
        "  return (class_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sShBOt2BfC5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bd02de5-9b63-4462-ab2c-aaddc4b932cb"
      },
      "source": [
        "train_x, train_y, test_x, test_y = dataset_splitter(iris)\n",
        "samples_0=[]\n",
        "samples_1=[]\n",
        "samples_2=[]\n",
        "for i,row in enumerate(train_x):\n",
        "  if train_y[i]==0:    \n",
        "    samples_0.append(list(row))\n",
        "  elif train_y[i]==1:\n",
        "    samples_1.append(list(row))\n",
        "  elif train_y[i]==2:\n",
        "    samples_2.append(list(row))\n",
        "samples_0 = (np.array(samples_0),np.array([0]*len(samples_0)))  # data with only samples from class:0\n",
        "samples_1 = (np.array(samples_1),np.array([1]*len(samples_1)))  # data with only samples from class:1\n",
        "samples_2 = (np.array(samples_2),np.array([2]*len(samples_2)))  # data with only samples from class:2\n",
        "\n",
        "set_0, set_1, set_2 = mean_var_calculator(samples_0[0]), mean_var_calculator(samples_1[0]), mean_var_calculator(samples_2[0])\n",
        "y_pred=[]\n",
        "\n",
        "for i,row in enumerate(test_x):\n",
        "  y_pred.append(predict(row, set_0, set_1, set_2))\n",
        "y_pred=np.array(y_pred)\n",
        "print ('accuracy of the model is {}'.format((y_pred==test_y).mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the model is 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8RrMTaAN2tL",
        "colab_type": "text"
      },
      "source": [
        "**Comparison with builtin model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBYrIqppYMWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4uDvk4EZpWG",
        "colab_type": "text"
      },
      "source": [
        "**Steps:** \n",
        "  1. fit the model on the train_x\n",
        "  2. Make predictions using inbuilt functions and print the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqhelXaNaPVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1907159e-0c57-41b8-c423-090d58fef09a"
      },
      "source": [
        "model.fit(train_x,train_y)\n",
        "predictions = model.predict(test_x)\n",
        "\n",
        "correct_predictions = (test_y==predictions).sum()\n",
        "accuracy = correct_predictions/float(len(test_x))\n",
        "print ('accuracy of using inbuilt model is {}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of using inbuilt model is 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxmZNKJzS4WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}